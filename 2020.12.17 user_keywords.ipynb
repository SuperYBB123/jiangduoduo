{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 计算文章关键词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.read_csv('../users30Days_1203.csv')\n",
    "item_data = pd.read_csv('../essays_keywords1204.csv')\n",
    "item_data = item_data[['itemid','最终关键词权重']]\n",
    "\n",
    "#useritem_join = pd.read_csv('../1203_40%.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_filterData = pd.DataFrame(useritem_join['deviceid'].unique(),columns=['deviceid'])\n",
    "#item_filterData = pd.DataFrame(useritem_join['itemid'].unique(),columns=['itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_data = pd.merge(user_data,user_filterData,on='deviceid')\n",
    "#item_data = pd.merge(item_data,item_filterData,on='itemid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = KeyedVectors.load_word2vec_format('./model_size100_mincount50_title3.vector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 处理符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_symbols(data):\n",
    "    key_words = data.replace('\\'','').replace('(','').replace(')','').replace('[','').replace(']','').replace(' ','').split(',')\n",
    "    key_dict={}\n",
    "    for i in range(int(len(key_words)/2)):\n",
    "        key_dict[key_words[2*i]]=float(key_words[2*i+1])/float(key_words[1])\n",
    "    return key_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JDD\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "my bar!: 100%|████████████████████████████████████████████████████████████████| 21043/21043 [00:00<00:00, 88652.32it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"my bar!\")\n",
    "item_data['KeyWords_WithWeight'] = item_data['最终关键词权重'].progress_apply(lambda x: drop_symbols(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 计算文章关键词向量(embedding vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_essay_vectors(data):\n",
    "    word_vector = np.zeros([1,100],dtype=np.float32)\n",
    "    count = 0\n",
    "    for word in data.keys():\n",
    "        if word in vec.index2word:\n",
    "            count+=1\n",
    "            word_vector+=vec[word]\n",
    "    if count:\n",
    "        return word_vector/count\n",
    "    else:\n",
    "        return word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 21043/21043 [00:05<00:00, 3694.71it/s]\n"
     ]
    }
   ],
   "source": [
    "essay_array = np.empty((item_data.shape[0],100))\n",
    "for i in tqdm(range(item_data.shape[0])):\n",
    "    essay_array[i]= compute_essay_vectors(item_data['KeyWords_WithWeight'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 生成文章词向量数据，并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_data = pd.concat([item_data['itemid'],pd.DataFrame(essay_array, columns=['essayVectors_'+str(i) for i in range(100)])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_data.to_csv('./essay_vectors1203.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 计算用户关键词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合并用户数据和文章数据\n",
    "data = user_data.merge(item_data,on='itemid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 提取用户关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_keywords(data):\n",
    "    a = {}\n",
    "    for i in range(data.shape[0]):\n",
    "        a.update(data['KeyWords_WithWeight'].iloc[i])\n",
    "    b = sorted(a.keys(),key=lambda x: x[1], reverse=True)[0:30]\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "my bar!: 100%|███████████████████████████████████████████████████████████████| 137304/137304 [00:22<00:00, 6111.52it/s]\n"
     ]
    }
   ],
   "source": [
    "#tqdm.pandas(desc=\"my bar!\")\n",
    "user_keywords = data.groupby('deviceid').progress_apply(lambda x: extract_user_keywords(x))\n",
    "user_keywords = user_keywords.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存用户关键词数据\n",
    "#user_keywords.to_csv('./users_keywords_1204.csv',encoding='utf-8_sig')\n",
    "#保存用户关键词数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 计算用户关键词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_user_vectors(data):\n",
    "    word_vector = np.zeros([1,100],dtype=np.float32)\n",
    "    count = 0\n",
    "    for word in data:\n",
    "        if word in vec.index2word:\n",
    "            count+=1\n",
    "            word_vector+=vec[word]\n",
    "    if count:\n",
    "        return word_vector/count\n",
    "    else:\n",
    "        return word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 137304/137304 [03:10<00:00, 720.08it/s]\n"
     ]
    }
   ],
   "source": [
    "user_array = np.zeros((user_keywords.shape[0],100))\n",
    "for i in tqdm(range(user_keywords.shape[0])):\n",
    "    user_array[i]= compute_user_vectors(user_keywords[0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 保存用户关键词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 181 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_vectors = pd.concat([user_keywords[['deviceid']],pd.DataFrame(user_array,columns=['userVectors_'+str(i) for i in range(100)])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vectors.to_csv('./user_vectors1203.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
